{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f36f28-c8eb-4e21-bed4-1c3c575fc60e",
   "metadata": {},
   "source": [
    "## Read in Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32f9b7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea52a25d-a873-45fc-9c33-332deea00146",
   "metadata": {},
   "source": [
    "## Define import path for all treated pieces of data and export path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c58e81ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python code assigns file paths to three data files:\n",
    "# Facebook Data: path_fb points to \"final_facebook.csv\" in the \"Processed Data\" directory.\n",
    "# YouTube Data: path_yt points to \"final_youtube.csv\" in the \"Processed Data\" directory.\n",
    "# Outdoor Data: path_outdoor points to \"final_outdoor.csv\" in the \"Processed Data\" directory.\n",
    "# These file locations will be used to retrieve the processed data files later on, either for further analysis or inclusion in a final database.\n",
    "\n",
    "path_fb = r'C:/Users/drvis/Downloads/MMM-2/Processed Data/final_facebook.csv'\n",
    "\n",
    "path_yt = r'C:/Users/drvis/Downloads/MMM-2/Processed Data/final_youtube.csv'\n",
    "\n",
    "path_outdoor = r'C:/Users/drvis/Downloads/MMM-2/Processed Data/final_outdoor.csv'\n",
    "\n",
    "# STUDENT INPUT REQUIRED - Modify path directly below for location of the 06a. All Other Variables.csv file on your laptop/desktop\n",
    "path_other_variables = r'C:/Users/drvis/Downloads/MMM-2/06a. All Other Variables (1).csv'\n",
    "\n",
    "export_data_path = 'C:/Users/drvis/Downloads/MMM-2/Processed Data/'\n",
    "file_name = 'final_database.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0357c856",
   "metadata": {},
   "source": [
    "## Read in Treated Facebook/Instagram, YouTube, and Outdoor Campaign Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e6e6173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python code is intended to read in the processed data from CSV files into Pandas DataFrames. It reads four separate CSV files:\n",
    "# df_fb: Loads the processed Facebook data from the file specified in `path_fb` into a DataFrame with the name `df_fb`.\n",
    "# df_yt: Imports the processed YouTube data from the file specified in `path_yt` into a DataFrame named `df_yt`.\n",
    "# df_outdoor: Fetches the processed outdoor data from the file specified in `path_outdoor` into a DataFrame named `df_outdoor`.\n",
    "# df_other_vars: Loads the additional variables data from the file specified in `path_other_variables` into a DataFrame named `df_other_vars`.\n",
    "\n",
    "df_fb = pd.read_csv(path_fb)\n",
    "df_yt = pd.read_csv(path_yt)\n",
    "df_outdoor = pd.read_csv(path_outdoor)\n",
    "df_other_vars = pd.read_csv(path_other_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71dc0ca0-9341-47a5-a0ef-1ad7e412a0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "week_starting_date                object\n",
       "sales                            float64\n",
       "bing_brand_search_clicks         float64\n",
       "bing_brand_search_spend          float64\n",
       "blackfriday_dummy                  int64\n",
       "covid_trend                      float64\n",
       "google_brand_search_clicks       float64\n",
       "google_brand_search_imp          float64\n",
       "google_brand_search_spend        float64\n",
       "google_display_clicks            float64\n",
       "google_display_imp               float64\n",
       "google_display_spend             float64\n",
       "google_nonbrand_search_clicks    float64\n",
       "google_nonbrand_search_imp       float64\n",
       "google_nonbrand_search_spend     float64\n",
       "google_video_clicks              float64\n",
       "google_video_imp                 float64\n",
       "google_video_spend               float64\n",
       "gwp_units_distributed              int64\n",
       "launch_fragrance_trend           float64\n",
       "launch_makeup_trend              float64\n",
       "launch_skincare_trend            float64\n",
       "market_sales                     float64\n",
       "mothersday_dummy                   int64\n",
       "nongoogle_display_spend          float64\n",
       "nongoogle_video_spend            float64\n",
       "pinterest_awareness_imp          float64\n",
       "pinterest_awareness_spend        float64\n",
       "pinterest_conversion_imp         float64\n",
       "pinterest_conversion_spend       float64\n",
       "print_coop_spend                 float64\n",
       "print_pure_spend                 float64\n",
       "samples_quantity_distributed       int64\n",
       "snap_awareness_imp               float64\n",
       "snap_awareness_spend             float64\n",
       "snap_conversion_imp              float64\n",
       "snap_conversion_spend            float64\n",
       "tiktok_awareness_imp             float64\n",
       "tiktok_awareness_spend           float64\n",
       "tv_coop_spend                    float64\n",
       "tv_pure_imp                      float64\n",
       "tv_pure_spend                    float64\n",
       "vday_dummy                         int64\n",
       "xmas_dummy                         int64\n",
       "youtube_video_spend              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This Python code prints the types of data that each column in the table called \"df_other_vars\" contains. It does this by using the \".dtypes\" option.\n",
    "# Knowing the data types in each column helps us understand how the data is stored and used.\n",
    "\n",
    "df_other_vars.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e7ca4be-f1bf-43b6-b60d-321a74a156d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we're using Python code to change the 'week_starting_date' column in several DataFrames (df_fb, df_yt, df_outdoor, df_other_vars) into datetime format.\n",
    "# This is done with the pd.to_datetime() function.\n",
    "# Overall, this change makes the data ready for analysis and combining it with data from other sources based on time.\n",
    "df_fb['week_starting_date'] = pd.to_datetime(df_fb['week_starting_date'])\n",
    "df_yt['week_starting_date'] = pd.to_datetime(df_yt['week_starting_date'])\n",
    "df_outdoor['week_starting_date'] = pd.to_datetime(df_outdoor['week_starting_date'])\n",
    "df_other_vars['week_starting_date'] = pd.to_datetime(df_other_vars['week_starting_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116cc94e-230e-4e72-9635-868268061ac6",
   "metadata": {},
   "source": [
    "## Check date ranges of dataframes - are they your modeling timeframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fad93f2-380a-4f05-953c-599a42e62ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first week of Facebook data:2019-01-07 00:00:00\n",
      "last week of Facebook data:2020-12-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# This Python code finds the start date of the first week and the start date of the last week in the Facebook data stored in the DataFrame `df_fb`.\n",
    "# `df_fb['week_starting_date'].min()`: It finds the earliest date in the `week_starting_date` column of the DataFrame.\n",
    "# - `df_fb['week_starting_date'].max()`: It finds the latest date in the `week_starting_date` column of the DataFrame.\n",
    "# The printed output includes the first and last weeks of the Facebook data, providing insights into the time period covered by the dataset.\n",
    "\n",
    "print('first week of Facebook data:' + str(df_fb['week_starting_date'].min()))\n",
    "print('last week of Facebook data:' + str(df_fb['week_starting_date'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa8f818-4056-4188-a39a-78e9a83d6f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First week of YouTube data:2019-01-07 00:00:00\n",
      "Last week of YouTube data:2020-12-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# STUDENT INPUT REQUIRED - Create similar code as above to print and check YouTube date range\n",
    "\n",
    "print('First week of YouTube data:' + str(df_yt['week_starting_date'].min()))\n",
    "print('Last week of YouTube data:' + str(df_yt['week_starting_date'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7cbeb50-a6dc-41e2-8836-43fff704bbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First week of Outdoor Campaign data:2019-01-07 00:00:00\n",
      "Last week of Outdoor Campaign data:2020-12-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# STUDENT INPUT REQUIRED - Create similar code as above to print and check Outdoor Campaign date range\n",
    "\n",
    "print('First week of Outdoor Campaign data:' + str(df_outdoor['week_starting_date'].min()))\n",
    "print('Last week of Outdoor Campaign data:' + str(df_outdoor['week_starting_date'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67b074bb-3553-476c-8d28-78ad57ab0db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First week of All Other Variables data:2019-01-07 00:00:00\n",
      "Last week of All Other Variables data:2020-12-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# STUDENT INPUT REQUIRED - Create similar code as above to print and check All Other Variables file date range\n",
    "\n",
    "print('First week of All Other Variables data:' + str(df_other_vars['week_starting_date'].min()))\n",
    "print('Last week of All Other Variables data:' + str(df_other_vars['week_starting_date'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4cf04a-1f46-45c0-97f7-899b45f5def8",
   "metadata": {},
   "source": [
    "## Perform join of all 4 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04765444-0d79-4e78-be57-727f5ab8eeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python code is intended to merge multiple DataFrames (df_fb, df_yt, df_outdoor) with the DataFrame df_other_vars based on the 'week_starting_date' column.\n",
    "# Line 1 code combines the DataFrames `df_other_vars` and `df_fb` using a \"left join\" on the `week_starting_date` column. This means that all rows from `df_other_vars` will be present in the merged DataFrame, even if there is no matching row in `df_fb`.\n",
    "# Line 2 code merges the result of Line 1 (`df_total`) with the DataFrame `df_yt` using a \"left join\" on the `week_starting_date` column. Again, all rows from `df_total` will be included in the merged DataFrame, regardless of matches in `df_yt`.\n",
    "# Line 3 code merges the result of Line 2 (`df_total`) with the DataFrame `df_outdoor` using a \"left join\" on the `week_starting_date` column. This completes the process of combining multiple DataFrames based on a common date column, ensuring that all relevant information is available for analysis.\n",
    "\n",
    "df_total = df_other_vars.merge(df_fb, on= 'week_starting_date', how='left')\n",
    "\n",
    "df_total = df_total.merge(df_yt, on= 'week_starting_date', how='left')\n",
    "\n",
    "df_total = df_total.merge(df_outdoor, on= 'week_starting_date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3358de11-9b3f-4575-b00b-53415e6ce992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following Python code is designed to perform calculations on the sum of numeric values from the previous dataframes (df_total, df_other_vars, df_fb, df_yt, df_outdoor).\n",
    "# Initially, it sets the index of the df_total dataframe to the column 'week_starting_date'.\n",
    "# It then calculates the total sum of numeric values in the df_total dataframe.\n",
    "# By subtracting the combined sum of numeric values from the other dataframes (df_other_vars, df_fb, df_yt, df_outdoor) from this total sum.\n",
    "# Essentially, it calculates the difference between the total sum of one dataframe (df_total) and the sum of values from multiple other dataframes (df_other_vars, df_fb, df_yt, df_outdoor).\n",
    "\n",
    "df_total = df_total.set_index('week_starting_date')\n",
    "\n",
    "# STUDENT COMMENT REQUIRED - write a short summary of what the python code in this cell is intended to do\n",
    "(df_total.sum(numeric_only=True).sum() - \n",
    "          (df_other_vars.sum(numeric_only=True).sum() + \n",
    "           df_fb.sum(numeric_only=True).sum() + \n",
    "           df_yt.sum(numeric_only=True).sum() + \n",
    "           df_outdoor.sum(numeric_only=True).sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa42253-fd29-4c2a-b1ae-99f555cf9147",
   "metadata": {},
   "source": [
    "## Peform check of final table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2e788ad-d262-4e8f-8b2b-e772292b0153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final totals match\n"
     ]
    }
   ],
   "source": [
    "# The Python code provided here calculates the absolute difference between the total sum of numeric values in the df_total dataframe and the combined sum of numeric values from other specified dataframes like df_other_vars, df_fb, df_yt, and df_outdoor.\n",
    "# After obtaining this absolute difference, it is then divided by the total sum of numeric values in the df_total dataframe.\n",
    "# The resulting value is then compared to a threshold of 0.000001. If the resulting value is less than this threshold, the code prints 'Final totals match', indicating that the total sums from df_total and the other specified dataframes are very close.\n",
    "# If the resulting value is greater than or equal to the threshold, it prints 'Final totals DO NOT match - revisit treatment', suggesting that there may be discrepancies in the data treatment that need to be reviewed and addressed.\n",
    "# In summary, this code performs a validation check to ensure the consistency of total sums across the different dataframes mentioned.\n",
    "\n",
    "if abs(df_total.sum(numeric_only=True).sum() - \n",
    "          (df_other_vars.sum(numeric_only=True).sum() + \n",
    "           df_fb.sum(numeric_only=True).sum() + \n",
    "           df_yt.sum(numeric_only=True).sum() + \n",
    "           df_outdoor.sum(numeric_only=True).sum()))/df_total.sum().sum() <0.000001:\n",
    "    print('Final totals match')\n",
    "else:\n",
    "    print('Final totals DO NOT match - revisit treatment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadfd2ee-23a3-451a-81f9-d31d8a10645e",
   "metadata": {},
   "source": [
    "## Export processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c77874de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python code is intended to export the DataFrame df_total to a CSV file.\n",
    "# df_total.to_csv(export_data_path + file_name): This method exports the data from the DataFrame df_total to a CSV (Comma-Separated Values) file.\n",
    "# The export_data_path variable specifies the directory path where the CSV file will be saved, and the file_name variable specifies the name of the CSV file.\n",
    "\n",
    "\n",
    "df_total.to_csv(export_data_path + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b652252-c331-4ddf-9f21-ddcf3dee158b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "829f8a924dbb286848138480efde3b946ad773cb919de7a1afee309cd95525df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
